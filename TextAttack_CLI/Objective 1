# Objective 1 (train using textfooler, test against BAE) (Completed)
# Task: Sentiment Analysis
# adversarially train the lstm model using imdb dataset from samples generated by textfooler framework
textattack train --model lstm --dataset imdb --attack textfooler --check-robustness --max-length 2500 --batch-size 64 --epochs 50
# output: trained model (note this path and pass it into the next snippet)
# /home/grads/iashiq5/venv/Project5984/lib64/python3.6/site-packages/outputs/training/lstm-imdb-2021-04-10-21-47-21-057164

# evaluate the model
textattack eval --num-examples 1000 --model /home/grads/iashiq5/venv/Project5984/lib64/python3.6/site-packages/outputs/training/lstm-imdb-2021-04-10-21-47-21-057164
"""
textattack: Got 1000 predictions.
textattack: Correct 768/1000 (76.80%)
"""

# Objective 1 (traing using textfooler, test against BAE)
# check whether the adversarially trained model is robust against BAE framework
# attack "adversarially trained lstm model on imdb dataset" against adversarial samples generated using BAE framework on imdb dataset
textattack attack --recipe bae --num-examples 1000 \
--model /home/grads/iashiq5/venv/Project5984/lib64/python3.6/site-packages/outputs/training/lstm-imdb-2021-04-10-21-47-21-057164 \
 --log-to-csv
# note the output of nohup.out file and also attack logs
# path: /home/grads/iashiq5/venv/Project5984/lib64/python3.6/site-packages/outputs/training/lstm-imdb-2021-04-10-21-47-21-057164_bae_2021-04-15-00-41.csv
"""
+-------------------------------+--------+
| Attack Results                |        |
+-------------------------------+--------+
| Number of successful attacks: | 566    |
| Number of failed attacks:     | 202    |
| Number of skipped attacks:    | 232    |
| Original accuracy:            | 76.8%  |
| Accuracy under attack:        | 20.2%  |
| Attack success rate:          | 73.7%  |
| Average perturbed word %:     | 3.99%  |
| Average num. words per input: | 226.15 |
| Avg num queries:              | 439.04 |
+-------------------------------+--------+
textattack: Attack time: 22136.80638194084s
"""

# Objective 1 (traing using textfooler, test against BAE)
# check how the old untrained model performed against BAE
textattack attack --recipe bae --num-examples 1000 --model lstm-imdb --log-to-csv
# path: /home/grads/iashiq5/venv/Project5984/lib64/python3.6/site-packages/outputs/attacks/lstm-imdb_bae_2021-04-15-10-17.csv
"""
+-------------------------------+--------+
| Attack Results                |        |
+-------------------------------+--------+
| Number of successful attacks: | 681    |
| Number of failed attacks:     | 139    |
| Number of skipped attacks:    | 180    |
| Original accuracy:            | 82.0%  |
| Accuracy under attack:        | 13.9%  |
| Attack success rate:          | 83.05% |
| Average perturbed word %:     | 2.56%  |
| Average num. words per input: | 226.15 |
| Avg num queries:              | 490.36 |
+-------------------------------+--------+
textattack: Attack time: 15759.985489368439s
"""