# Objective 1 (train using textbugger, test against others)
# Task: Sentiment Analysis
# adversarially train the lstm model using imdb dataset from samples generated by textbugger framework

textattack train --model lstm --dataset imdb --pct-dataset 0.1 --max-length 2500 --batch-size 32 --attack textbugger --attack-period 100 --num-clean-epochs 50

# output: trained model (note this path and pass it into the next snippet)
# /home/grads/iashiq5/venv/Project5984/lib/python3.6/site-packages/outputs/training/lstm-imdb-2021-04-24-00-35-38-998054/

# evaluate the model
textattack eval --num-examples 1000 --model /home/grads/iashiq5/venv/Project5984/lib/python3.6/site-packages/outputs/training/lstm-imdb-2021-04-24-00-35-38-998054/
"""
textattack: Got 1000 predictions.
textattack: Correct 752/1000 (75.20%)
"""

# check performance of the adversarially trained model is robust against other frameworks
# attack "adversarially trained previous model" against adversarial samples generated using other framework on imdb dataset
textattack attack --recipe <var> --num-examples 1000 --model /home/grads/iashiq5/venv/Project5984/lib/python3.6/site-packages/outputs/training/lstm-imdb-2021-04-24-00-35-38-998054/ --log-to-csv
"""
+-------------------------------+--------+
| Attack Results                |        |
+-------------------------------+--------+
| Number of successful attacks: | 813    |
| Number of failed attacks:     | 0      |
| Number of skipped attacks:    | 187    |
| Original accuracy:            | 81.3%  |
| Accuracy under attack:        | 0.0%   |
| Attack success rate:          | 100.0% |
| Average perturbed word %:     | 3.12%  |
| Average num. words per input: | 226.15 |
| Avg num queries:              | 401.03 |
+-------------------------------+--------+
textattack: Attack time: 2449.2378599643707s
"""

# train both the models non-adversarially

textattack train --model lstm --dataset imdb --pct-dataset 0.1 --max-length 2500 --batch-size 32
# /home/grads/iashiq5/venv/Project5984/lib/python3.6/site-packages/outputs/training/lstm-imdb-2021-04-24-00-46-08-656001/

textattack eval --num-examples 1000 --model /home/grads/iashiq5/venv/Project5984/lib/python3.6/site-packages/outputs/training/lstm-imdb-2021-04-24-00-46-08-656001/
# textattack: Correct 751/1000 (75.10%)

textattack attack --recipe <var> --num-examples 1000 --model /home/grads/iashiq5/venv/Project5984/lib/python3.6/site-packages/outputs/training/lstm-imdb-2021-04-24-00-46-08-656001/ --log-to-csv




textattack train --model cnn --dataset imdb --pct-dataset 0.1 --max-length 2500 --batch-size 32
# /home/grads/iashiq5/venv/Project5984/lib/python3.6/site-packages/outputs/training/cnn-imdb-2021-04-24-01-34-13-141990/

textattack eval --num-examples 1000 --model /home/grads/iashiq5/venv/Project5984/lib/python3.6/site-packages/outputs/training/cnn-imdb-2021-04-24-01-34-13-141990/
# textattack: Correct 811/1000 (81.10%)

# check how it performed against other attack recipes
textattack attack --recipe <var> --num-examples 1000 --model /home/grads/iashiq5/venv/Project5984/lib/python3.6/site-packages/outputs/training/cnn-imdb-2021-04-24-01-34-13-141990/ --log-to-csv




"""
+-------------------------------+--------+
| Attack Results                |        |
+-------------------------------+--------+
| Number of successful attacks: | 810    |
| Number of failed attacks:     | 0      |
| Number of skipped attacks:    | 190    |
| Original accuracy:            | 81.0%  |
| Accuracy under attack:        | 0.0%   |
| Attack success rate:          | 100.0% |
| Average perturbed word %:     | 2.19%  |
| Average num. words per input: | 226.15 |
| Avg num queries:              | 332.62 |
+-------------------------------+--------+
textattack: Attack time: 1454.0820834636688s
"""